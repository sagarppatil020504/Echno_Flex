{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------\n",
    "# Step 1: Data Collection\n",
    "# -------------------------------------\n",
    "\n",
    "# Fetch stock price data\n",
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data['Date'] = data.index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "# Fetch news data for sentiment analysis\n",
    "def get_news_sentiment(keyword, start_date, end_date):\n",
    "    # Example API: Replace with your News API Key\n",
    "    API_KEY = 'YOUR_NEWSAPI_KEY'\n",
    "    url = f'https://newsapi.org/v2/everything?q={keyword}&from={start_date}&to={end_date}&apiKey={API_KEY}'\n",
    "    response = requests.get(url).json()\n",
    "    articles = response.get('articles', [])\n",
    "    \n",
    "    sentiments = []\n",
    "    for article in articles:\n",
    "        title = article['title']\n",
    "        description = article.get('description', '')\n",
    "        text = f\"{title} {description}\"\n",
    "        sentiment = TextBlob(text).sentiment.polarity\n",
    "        sentiments.append(sentiment)\n",
    "    return np.mean(sentiments) if sentiments else 0\n",
    "\n",
    "# Get macroeconomic data (example: simulated data for illustration)\n",
    "def get_macro_factors():\n",
    "    # Replace this with actual macroeconomic data sources\n",
    "    return {\"interest_rate\": 3.5, \"inflation\": 4.2, \"gdp_growth\": 2.7}\n",
    "\n",
    "# -------------------------------------\n",
    "# Step 2: Data Preprocessing\n",
    "# -------------------------------------\n",
    "\n",
    "# Fetch stock data\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2024-12-01\"\n",
    "stock_data = get_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "# Add technical indicators\n",
    "stock_data['SMA_20'] = stock_data['Close'].rolling(window=20).mean()\n",
    "stock_data['RSI'] = 100 - (100 / (1 + stock_data['Close'].pct_change().rolling(window=14).mean() /\n",
    "                                      stock_data['Close'].pct_change().rolling(window=14).std()))\n",
    "stock_data['MACD'] = stock_data['Close'].ewm(span=12).mean() - stock_data['Close'].ewm(span=26).mean()\n",
    "\n",
    "# Add sentiment analysis\n",
    "stock_data['Sentiment'] = stock_data['Date'].apply(\n",
    "    lambda x: get_news_sentiment(ticker, x.strftime('%Y-%m-%d'), x.strftime('%Y-%m-%d'))\n",
    ")\n",
    "\n",
    "# Add macroeconomic factors\n",
    "macro_factors = get_macro_factors()\n",
    "stock_data['Interest_Rate'] = macro_factors['interest_rate']\n",
    "stock_data['Inflation'] = macro_factors['inflation']\n",
    "stock_data['GDP_Growth'] = macro_factors['gdp_growth']\n",
    "\n",
    "# Drop NaN values\n",
    "stock_data.dropna(inplace=True)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(stock_data[['Close', 'SMA_20', 'RSI', 'MACD', 'Sentiment',\n",
    "                                               'Interest_Rate', 'Inflation', 'GDP_Growth']])\n",
    "\n",
    "# Create time-series data for LSTM\n",
    "def create_sequences(data, seq_length=60):\n",
    "    x, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i, 0])  # Predict the 'Close' price\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "seq_length = 60\n",
    "x, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "train_size = int(len(x) * 0.8)\n",
    "x_train, x_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# -------------------------------------\n",
    "# Step 3: Build and Train LSTM Model\n",
    "# -------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test))\n",
    "\n",
    "# -------------------------------------\n",
    "# Step 4: Evaluate the Model\n",
    "# -------------------------------------\n",
    "\n",
    "# Predict on test data\n",
    "predicted_prices = model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(np.concatenate((predicted_prices, np.zeros((predicted_prices.shape[0], 7))), axis=1))[:, 0]\n",
    "\n",
    "# Actual prices\n",
    "actual_prices = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], 7))), axis=1))[:, 0]\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(np.mean((predicted_prices - actual_prices) ** 2))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# Step 5: Visualization\n",
    "# -------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actual_prices, label=\"Actual Prices\", color='blue')\n",
    "plt.plot(predicted_prices, label=\"Predicted Prices\", color='red')\n",
    "plt.title(f\"{ticker} Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
